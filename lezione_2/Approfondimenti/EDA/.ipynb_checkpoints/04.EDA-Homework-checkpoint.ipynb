{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science and Machine Learning\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img width=\"699\" alt=\"image\" src=\"https://user-images.githubusercontent.com/49638680/159042792-8510fbd1-c4ac-4a48-8320-bc6c1a49cdae.png\">\n",
    "</p>\n",
    "\n",
    "---\n",
    "\n",
    "## Exploratory Data Analysis - Homework\n",
    "\n",
    "The aim of this notebook is to give you an exercise to perform an exploratory data analysis in order to extract some useful information hidden in data.\n",
    "\n",
    "We are going to analyse the [Tennis dataset](http://tennis-data.co.uk). In order to guide your analysis, you should try to approach the problem by wondering some questions. The role of the analysis is to find the answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen  \n",
    "import os.path as osp\n",
    "import os\n",
    "import logging\n",
    "import zipfile\n",
    "from glob import glob\n",
    "logging.getLogger().setLevel('INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url_str, path):\n",
    "    url = urlopen(url_str)\n",
    "    output = open(path, 'wb')       \n",
    "    output.write(url.read())\n",
    "    output.close()  \n",
    "    \n",
    "def extract_file(archive_path, target_dir):\n",
    "    zip_file = zipfile.ZipFile(archive_path, 'r')\n",
    "    zip_file.extractall(target_dir)\n",
    "    zip_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2000/2000.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2001/2001.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2002/2002.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2003/2003.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2004/2004.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2005/2005.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2006/2006.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2007/2007.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2008/2008.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2009/2009.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2010/2010.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2011/2011.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2012/2012.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2013/2013.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2014/2014.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2015/2015.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2016/2016.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2017/2017.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2018/2018.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2007w/2007.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2008w/2008.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2009w/2009.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2010w/2010.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2011w/2011.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2012w/2012.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2013w/2013.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2014w/2014.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2015w/2015.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2016w/2016.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2017w/2017.zip\n",
      "INFO:root:downloading & extracting file http://tennis-data.co.uk/2018w/2018.zip\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'xlrd'. Install xlrd >= 1.0.0 for Excel support Use pip or conda to install xlrd.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m ATP_FILES \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(glob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/*.xls*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m ATP_DIR))\n\u001b[1;32m     20\u001b[0m WTA_FILES \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(glob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/*.xls*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m WTA_DIR))\n\u001b[0;32m---> 22\u001b[0m df_atp \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([pd\u001b[38;5;241m.\u001b[39mread_excel(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m ATP_FILES], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     23\u001b[0m df_wta \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([pd\u001b[38;5;241m.\u001b[39mread_excel(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m WTA_FILES], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     25\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m matches ATP in df_atp\u001b[39m\u001b[38;5;124m\"\u001b[39m, df_atp\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     19\u001b[0m ATP_FILES \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(glob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/*.xls*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m ATP_DIR))\n\u001b[1;32m     20\u001b[0m WTA_FILES \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(glob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/*.xls*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m WTA_DIR))\n\u001b[0;32m---> 22\u001b[0m df_atp \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m ATP_FILES], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     23\u001b[0m df_wta \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([pd\u001b[38;5;241m.\u001b[39mread_excel(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m WTA_FILES], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     25\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m matches ATP in df_atp\u001b[39m\u001b[38;5;124m\"\u001b[39m, df_atp\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/lectures/lib/python3.10/site-packages/pandas/util/_decorators.py:299\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting with Pandas version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m all arguments of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00marguments\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be keyword-only\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m     )\n\u001b[1;32m    298\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39mstacklevel)\n\u001b[0;32m--> 299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lectures/lib/python3.10/site-packages/pandas/io/excel/_base.py:336\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    335\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    339\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    340\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    341\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/lectures/lib/python3.10/site-packages/pandas/io/excel/_base.py:1131\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m=\u001b[39m engine\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options \u001b[38;5;241m=\u001b[39m storage_options\n\u001b[0;32m-> 1131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engines\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lectures/lib/python3.10/site-packages/pandas/io/excel/_xlrd.py:24\u001b[0m, in \u001b[0;36mXlrdReader.__init__\u001b[0;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03mReader using xlrd engine.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    passed to fsspec for appropriate URLs (see ``_get_filepath_or_buffer``)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     23\u001b[0m err_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstall xlrd >= 1.0.0 for Excel support\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 24\u001b[0m \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxlrd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr_msg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(filepath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options)\n",
      "File \u001b[0;32m~/miniconda3/envs/lectures/lib/python3.10/site-packages/pandas/compat/_optional.py:109\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, raise_on_missing, on_version)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raise_on_missing:\n\u001b[0;32m--> 109\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Missing optional dependency 'xlrd'. Install xlrd >= 1.0.0 for Excel support Use pip or conda to install xlrd."
     ]
    }
   ],
   "source": [
    "BASE_URL = 'http://tennis-data.co.uk'\n",
    "DATA_DIR = \"tennis_data\"\n",
    "ATP_DIR = './{}/ATP'.format(DATA_DIR)\n",
    "WTA_DIR = './{}/WTA'.format(DATA_DIR)\n",
    "\n",
    "ATP_URLS = [BASE_URL + \"/%i/%i.zip\" % (i,i) for i in range(2000,2019)]\n",
    "WTA_URLS = [BASE_URL + \"/%iw/%i.zip\" % (i,i) for i in range(2007,2019)]\n",
    "\n",
    "os.makedirs(osp.join(ATP_DIR, 'archives'), exist_ok=True)\n",
    "os.makedirs(osp.join(WTA_DIR, 'archives'), exist_ok=True)\n",
    "\n",
    "for files, directory in ((ATP_URLS, ATP_DIR), (WTA_URLS, WTA_DIR)):\n",
    "    for dl_path in files:\n",
    "        logging.info(\"downloading & extracting file %s\", dl_path)\n",
    "        archive_path = osp.join(directory, 'archives', osp.basename(dl_path))\n",
    "        download_file(dl_path, archive_path)\n",
    "        extract_file(archive_path, directory)\n",
    "    \n",
    "ATP_FILES = sorted(glob(\"%s/*.xls*\" % ATP_DIR))\n",
    "WTA_FILES = sorted(glob(\"%s/*.xls*\" % WTA_DIR))\n",
    "\n",
    "df_atp = pd.concat([pd.read_excel(f) for f in ATP_FILES], ignore_index=True)\n",
    "df_wta = pd.concat([pd.read_excel(f) for f in WTA_FILES], ignore_index=True)\n",
    "\n",
    "logging.info(\"%i matches ATP in df_atp\", df_atp.shape[0])\n",
    "logging.info(\"%i matches WTA in df_wta\", df_wta.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem description\n",
    "\n",
    "### The data\n",
    "The website‚Äã [‚Äãhttp://tennis-data.co.uk/alldata.php‚Äã](‚Äãhttp://tennis-data.co.uk/alldata.php‚Äã) gathers outcomes of both WTA‚Äã (Women Tennis Association)‚Äã and ATP ‚Äã(Association of Tennis Professionals - men only)‚Äã tennis games over several years.\n",
    "A short description of each variable can be found here : [http://www.tennis-data.co.uk/notes.txt](http://www.tennis-data.co.uk/notes.txt)\n",
    "\n",
    "### What is expected from you\n",
    "First of all, answer the following questions.\n",
    "\n",
    "#### Questions\n",
    "Please answer the following questions about the dataset with the appropriate line(s) of code.\n",
    "\n",
    "##### Example\n",
    "\n",
    "__Question‚Äã__: How many ATP matches are there in the dataset? \n",
    "\n",
    "__Answer‚Äã__: \n",
    "```python\n",
    "len(df_atp)\n",
    "```\n",
    "\n",
    "1. Who are the three ATP players with the most wins ?\n",
    "2. How many sets did the player ‚Äú‚ÄãFederer R.‚Äù win in total ?\n",
    "3. How many sets did the player ‚Äú‚ÄãFederer R.‚Äù win during the years 2016 and 2017 ?\n",
    "4. For each match, what is the percentage of victories of the winner in the past ?\n",
    "5. How are (differently) distributed wins of players in the age segments `[16-23]`, `[24-30]` `[30+]`?\n",
    "6. Does the behaviour in the previous answer changes between men and women?\n",
    "\n",
    "_Hint_: Careful with null values and how you handle them.\n",
    "\n",
    "#### Bonus points\n",
    "\n",
    "* your notebook contains graphics that are both interesting and pretty\n",
    "* we can go through your entire notebook without frowning\n",
    "* you teach us something cool üôÇ\n",
    "\n",
    "#### Free Analysis\n",
    "\n",
    "We would like you to perform some free analysis. For example study distributions, correlations, etc.\n",
    "\n",
    "---\n",
    "\n",
    "## Your Work\n",
    "\n",
    "Have fun!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lectures",
   "language": "python",
   "name": "lectures"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
